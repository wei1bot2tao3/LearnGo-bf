读多写少 适合缓存
大体上分成
    1.本地缓存
    2.分布式缓存 redis memcache

Beego API
：单个操作
：批量操作
：针对数字的自增自减

Go-cache
:单个操作
:针对数字的加减操作

如何处理过期时间的策略
1.每个key开一个goroutine盯着
缺点：key多了goroutine也就多了，
同时这些goroutine大多时候被阻塞住了

2.定期轮询，然后删除
创建cache时候，同时创建一个goroutine ,这个goroutine会检查
每一个检查key过期的时间，并且在过期后执行删除
要点：
   要控制检查间隔：过短影响用户，资源消耗过大
   要控制住遍历的资源开销：如果全部Key遍历一遍，那么可能消耗时间长，因为遍历时候要加锁所以会影响业务
   可以控制遍历时常
   可以遍历数量
轮训+Get 两种结合 防止一直没人get


3.永不过期，访问时候删除


Redis的过期处理：
get 时候检查是否过期
遍历key找出过期的删除

与sql.DB空闲连接关闭对比
Get懒惰关闭 只用了这个
只有在Get它时候才会关闭


优化手段 用ekit的延时队列

evict 回调与关闭

部分情况下，缓存中间件可以考虑提供CDC接口 change data capture 接口
类似与redis的subscribe
在本地缓存实现中，这种个接口主要就是缓存过期被删除的回调
核心 ：把变更前后的上下文都暴露出去

控制本地缓存内存
  淘汰算法
  两种策略：
     控制键值对数量：比如说只允许十万个键值对
     控制整体内存：需要计算每个对象的大小，然后累加
使用装饰器模式


利用你的API来Redis:
组合API
多个动作组合在一起，作为一个API来提供
这种组合API要注意安全： 线程安全。在本地实现加锁就可以，在Redis里要用lua脚本

缓存的面试要点：
缓存过期时间怎么控制？一共三种
定期删除过期缓存有什么注意？注意控制CPU开销，防止定期删除占用太多资源
为什么无法做到缓存一过期就删除？借助于缓存队列可以勉强做到。 不是很现实，
本地缓存如何避免占用内存？控制内存使用量，可以控制内存总量，可以控制键值对总数。
如何提供缓存的内存利用率？

缓存模式
常用的：
Cache Aside：
    什么都不用就是。
    把cache当作一个普通的业务源
    Cache和DB都依赖于业务逻辑
    采用singleflight
    不管怎么操作，redis或者mysql这种没有真正达成一致的方案，都是多大程度下容忍
    唯一可能是缓存中间件要实现分布式事物
    缺点：缓存和cache不一致

Read Through：
    业务代码只需要从Cache中读取数据，cache会在缓存不命中时候读取数据
    写数据的时候，业务代码需要自己写DB和ceach

Write Through:
    开发者只需要写入cache，cache自己会更新数据，缓存中间件会代替你

WriteBack:
    写缓存后，直接缓存，
    读缓存是，读完之后直接返回
    缓存过期后回去DB加载数据

refresh-ahead:
     你只更新到数据库 然后第四方更新到redis 获取还是从redis

    依赖于CDC接口：Change data capture
    数据库暴露数据库接口
    cache 或者第四方在监听到数据变更之后自动更新数据
    如果cache未命中，依旧刷新缓存的话，依然会出现并发

某些一定设计模式在一定程度下缓解数据一致性


缓存异常：
    缓存穿透：
        读请求对应的数据根本不存在，缓存、Db里都没有。每次都会落到DB上。
        场景：黑客
    缓存击穿：
        缓存中没有、DB里面有。严重是因为：某个Key访问量特别大，都去数据库查询可能压垮
        场景：某个key过期了，此时突然大量请求
    缓存雪崩：
        同一时刻大量Key过期，全都要查询DB
        场景：缓存预热时候，所有Key的过期场景都一样，所以会在同一时间

    解决思路：
        大量请求落到数据库，让这些请求尽量不会落到数据库里面

        single flight：
            在多个goroutine视图取加载通一个key对应数据的时候，只允许一个goroutine查询
            同一时刻不同Key的数量和实例数量相当。
            eg：同一时刻加载是个不同key的数据，部署三个实例，那么数据可的压力是10*3
            特征：热点越集中，效果越好
            组合 +read Through结合 见read_Through.go getV3
            实现1：
            实现2：
            对于V1版本，每个key都会独立地使用singleflight模式来加载数据并刷新缓存。这意味着对于每个key，如果有多个并发请求同时到达，只有一个请求会实际执行加载数据的操作，而其他请求会等待该请求完成并返回相同的结果。这可以避免多个请求同时触发重复的加载操作。
            对于V2版本，由于singleflight.Group实例g是在对象创建时就创建的，并在整个对象的生命周期中使用，因此对于一堆key的请求，它们会共享同一个singleflight.Group实例。这意味着如果多个并发请求同时到达，只有一个请求会实际执行加载数据的操作，而其他请求会等待该请求完成并返回相同的结果。这也可以避免多个请求同时触发重复的加载操作。


        缓存穿透---解决方案：
            1.使用single flight能够缓解问题，但是攻击者构造大量不同的不存在的key那么single flight的效果就不好
            2.数据库里根本没数据，缓存未命中就返回：
                    --缓存放全量数据，未命中就可以直接返回
                    --使用布尔过滤器或者bit array等结构，未命中时候在问一下这些结构
            3.缓存没有，不查DB，使用默认值
            4.在缓存未命中回表查询时候加限流器

            布尔过滤器面试：布尔过滤器告诉你没有肯定没有，告诉你有那么不一定有。

        缓存击穿--解决方案
            1.single flight，
            2.缓存未命中就使用默认值
            3.在参会数据库时加上限流器

        缓存雪崩--解决方案：
            设置key过期设置一个随机的偏移量  random_exporation_cache
            核心：不要让过期时间解决在一起

    面试要点：什么是缓存穿透、击穿、雪崩
             缓存模式有啥
             缓存穿透、雪崩、击穿和缓存模式有什么关系
             single flight有什么好处 只能控制单进程的goroutine
             为啥不支持全局的single flight 本质上变成分布式锁了
             缓存模式能不能解决缓存一致性的问题
             write-back有啥优缺点
             redis的八股文








